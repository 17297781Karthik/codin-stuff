{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:48:52.496259Z",
     "start_time": "2024-11-14T15:48:52.492686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f004db7b8fb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1fb73e-0920-4f84-a855-0eeaca0614d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw=set(stopwords.words('english'))\n",
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d03ae61-5d8d-4639-ba45-4f8d973327ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'than', 'on', 'yourself', 'there', 'doesn', 'll', 'wouldn', 't', 'we', 'under', \"couldn't\", \"shouldn't\", 'while', 'other', 'against', 'no', 'himself', 'this', 'not', 'me', 'ain', 'to', 'had', 'so', 'those', 'both', 'and', 'because', 'do', 'until', 'below', 'with', \"hadn't\", 'mustn', 'few', \"shan't\", 'whom', 'couldn', 'weren', 'if', \"aren't\", 'themselves', \"won't\", 'too', \"haven't\", 'through', 'that', 'been', 'from', \"doesn't\", \"mustn't\", 've', 'as', 'only', 'wasn', 'or', 'the', 'myself', 'are', 'above', 'over', 're', 'needn', 'am', 'up', 'him', 'into', 'some', 'itself', 'have', 'a', 'it', 'theirs', \"mightn't\", 'won', 'what', 'ours', 'hers', \"you're\", 'them', \"needn't\", 'most', \"you've\", 'for', 'why', 'did', 'she', 'which', 'down', 'now', 'hasn', 'my', 'by', 'in', 'don', 'very', 'i', \"don't\", 'has', 'having', 'here', 'off', 'their', 'these', 'm', 'aren', 'ma', 'again', 'should', 's', 'will', \"that'll\", 'yourselves', 'who', 'hadn', 'yours', 'd', \"hasn't\", 'its', 'ourselves', 'shouldn', 'were', 'is', 'out', 'own', 'of', 'nor', 'they', 'her', 'further', 'does', 'when', 'mightn', 'our', 'such', \"wouldn't\", \"didn't\", 'you', \"she's\", 'he', 'just', \"should've\", 'then', 'once', 'didn', \"you'll\", \"wasn't\", 'same', 'was', 'where', 'can', 'shan', 'any', 'your', 'after', \"isn't\", 'his', 'more', 'being', 'about', 'herself', 'all', 'how', \"it's\", 'isn', 'y', \"you'd\", 'at', 'before', 'between', 'be', 'haven', \"weren't\", 'during', 'but', 'an', 'o', 'each', 'doing'}\n"
     ]
    }
   ],
   "source": [
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e008fe3a-4724-4418-aa42-41ea7fa9cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1de030-48af-413c-9588-b6f9026e51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\karthik\n",
      "[nltk_data]     cse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\karthik\n",
      "[nltk_data]     cse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d21b79-78a0-44fd-a1ed-4662e9f1c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "strr=\"I am a sample sentence containing the stop words... I am a second sente. The tiger is one of the most brave animal in  the world\"\n",
    "sents=sent_tokenize(strr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e98f7b6d-29bc-47fd-b2ea-33acc6fed58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am a sample sentence containing the stop words...', 'I am a second sente.', 'The tiger is one of the most brave animal in  the world']\n"
     ]
    }
   ],
   "source": [
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edc569c-e5e1-4e51-bda6-df67b2e31c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am', 'a', 'sample', 'sentence', 'containing', 'the', 'stop', 'words', '...'], ['I', 'am', 'a', 'second', 'sente', '.'], ['The', 'tiger', 'is', 'one', 'of', 'the', 'most', 'brave', 'animal', 'in', 'the', 'world']]\n"
     ]
    }
   ],
   "source": [
    "word=[]\n",
    "for sent in sents:\n",
    "    word.append(word_tokenize(sent))\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1cf0b4-5302-4614-99c2-c980fea73939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'sample', 'sentence', 'containing', 'stop', 'words', '...', 'I', 'second', 'sente', '.', 'The', 'tiger', 'one', 'brave', 'animal', 'world']\n"
     ]
    }
   ],
   "source": [
    "final=[]\n",
    "for wd in word:\n",
    "    for w in wd:\n",
    "        \n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7482c657-d35c-43b0-baf6-77c6f0f5887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gr\n"
     ]
    }
   ],
   "source": [
    "ar=[1,2,1,2,1,1,8,9,5,1]\n",
    "\n",
    "if 1  in ar:\n",
    "    print('gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ae2de6-7870-46c9-9604-36c348ef62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843']\n",
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports of products hit by the\n",
      "  new taxes.\n",
      "      \"We wouldn't be able to do business,\" said a spokesman for\n",
      "  leading Japanese electronics firm Matsushita Electric\n",
      "  Industrial Co Ltd &lt;MC.T>.\n",
      "      \"If the tariffs remain in place for any length of time\n",
      "  beyond a few months it will mean the complete erosion of\n",
      "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
      "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
      "  Capel and Co>.\n",
      "      In Taiwan, businessmen and officials are also worried.\n",
      "      \"We are aware of the seriousness of the U.S. Threat against\n",
      "  Japan because it serves as a warning to us,\" said a senior\n",
      "  Taiwanese trade official who asked not to be named.\n",
      "      Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
      "  year, 95 pct of it with the U.S.\n",
      "      The surplus helped swell Taiwan's foreign exchange reserves\n",
      "  to 53 billion dlrs, among the world's largest.\n",
      "      \"We must quickly open our markets, remove trade barriers and\n",
      "  cut import tariffs to allow imports of U.S. Products, if we\n",
      "  want to defuse problems from possible U.S. Retaliation,\" said\n",
      "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>.\n",
      "      A senior official of South Korea's trade promotion\n",
      "  association said the trade dispute between the U.S. And Japan\n",
      "  might also lead to pressure on South Korea, whose chief exports\n",
      "  are similar to those of Japan.\n",
      "      Last year South Korea had a trade surplus of 7.1 billion\n",
      "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985.\n",
      "      In Malaysia, trade officers and businessmen said tough\n",
      "  curbs against Japan might allow hard-hit producers of\n",
      "  semiconductors in third countries to expand their sales to the\n",
      "  U.S.\n",
      "      In Hong Kong, where newspapers have alleged Japan has been\n",
      "  selling below-cost semiconductors, some electronics\n",
      "  manufacturers share that view. But other businessmen said such\n",
      "  a short-term commercial advantage would be outweighed by\n",
      "  further U.S. Pressure to block imports.\n",
      "      \"That is a very short-term view,\" said Lawrence Mills,\n",
      "  director-general of the Federation of Hong Kong Industry.\n",
      "      \"If the whole purpose is to prevent imports, one day it will\n",
      "  be extended to other sources. Much more serious for Hong Kong\n",
      "  is the disadvantage of action restraining trade,\" he said.\n",
      "      The U.S. Last year was Hong Kong's biggest export market,\n",
      "  accounting for over 30 pct of domestically produced exports.\n",
      "      The Australian government is awaiting the outcome of trade\n",
      "  talks between the U.S. And Japan with interest and concern,\n",
      "  Industry Minister John Button said in Canberra last Friday.\n",
      "      \"This kind of deterioration in trade relations between two\n",
      "  countries which are major trading partners of ours is a very\n",
      "  serious matter,\" Button said.\n",
      "      He said Australia's concerns centred on coal and beef,\n",
      "  Australia's two largest exports to Japan and also significant\n",
      "  U.S. Exports to that country.\n",
      "      Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
      "  trade stand-off continue.\n",
      "      Japan's ruling Liberal Democratic Party yesterday outlined\n",
      "  a package of economic measures to boost the Japanese economy.\n",
      "      The measures proposed include a large supplementary budget\n",
      "  and record public works spending in the first half of the\n",
      "  financial year.\n",
      "      They also call for stepped-up spending as an emergency\n",
      "  measure to stimulate the economy despite Prime Minister\n",
      "  Yasuhiro Nakasone's avowed fiscal reform program.\n",
      "      Deputy U.S. Trade Representative Michael Smith and Makoto\n",
      "  Kuroda, Japan's deputy minister of International Trade and\n",
      "  Industry (MITI), are due to meet in Washington this week in an\n",
      "  effort to end the dispute.\n",
      "  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\karthik\n",
      "[nltk_data]     cse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29264\\2699675305.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreuters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Print the first 10 file IDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreuters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreuters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreuters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    813\u001b[0m                 )\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# For data is scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Load Reuters dataset, which is commonly used for text classification\n",
    "print(reuters.fileids()[:10])  # Print the first 10 file IDs\n",
    "print(reuters.raw(reuters.fileids()[0]))\n",
    "import pandas as  pd \n",
    "import numpy as np \n",
    "df=pd.DataFrame(reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f219383-14e3-46b4-93af-ad05e3dd12ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
